{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8bf09bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "from mediapipe import solutions\n",
    "from mediapipe.tasks import python\n",
    "from mediapipe.tasks.python import vision\n",
    "from mediapipe.framework.formats import landmark_pb2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c65fd0ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_landmarks_on_image(rgb_image, detection_result):\n",
    "  pose_landmarks_list = detection_result.pose_landmarks\n",
    "  annotated_image = np.copy(rgb_image)\n",
    "\n",
    "  # Loop through the detected poses to visualize.\n",
    "  for idx in range(len(pose_landmarks_list)):\n",
    "    pose_landmarks = pose_landmarks_list[idx]\n",
    "\n",
    "    # Draw the pose landmarks.\n",
    "    pose_landmarks_proto = landmark_pb2.NormalizedLandmarkList()\n",
    "    pose_landmarks_proto.landmark.extend([\n",
    "      landmark_pb2.NormalizedLandmark(x=landmark.x, y=landmark.y, z=landmark.z) for landmark in pose_landmarks\n",
    "    ])\n",
    "    solutions.drawing_utils.draw_landmarks(\n",
    "      annotated_image,\n",
    "      pose_landmarks_proto,\n",
    "      solutions.pose.POSE_CONNECTIONS,\n",
    "      solutions.drawing_styles.get_default_pose_landmarks_style())\n",
    "  return annotated_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dfe8ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating the Landmark object\n",
    "base_options = python.BaseOptions(model_asset_path='../models/pose_landmarker_heavy.task')\n",
    "VisionRunningMode = mp.tasks.vision.RunningMode\n",
    "options = vision.PoseLandmarkerOptions(\n",
    "    base_options=base_options,\n",
    "    output_segmentation_masks=True,\n",
    "    running_mode=vision.RunningMode.VIDEO,\n",
    "    min_pose_detection_confidence=0.6,\n",
    "    min_pose_presence_confidence=0.7,\n",
    "    min_tracking_confidence=0.95,\n",
    ")\n",
    "detector = vision.PoseLandmarker.create_from_options(options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "159f6ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "VIDEO_PATH    = \"../data/raw\"\n",
    "OUTPUT_PATH   = \"../data/processed\"\n",
    "FILE_NAME = \"video0\"\n",
    "FILE_PATH = os.path.join(VIDEO_PATH, FILE_NAME + \".mp4\")\n",
    "\n",
    "cap = cv2.VideoCapture(FILE_PATH)\n",
    "if not cap.isOpened():\n",
    "    raise RuntimeError(f\"Could not open video file: {FILE_PATH}\")\n",
    "\n",
    "fps    = cap.get(cv2.CAP_PROP_FPS) or 30.0\n",
    "width  = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')              # or 'avc1', 'XVID', etc.\n",
    "out    = cv2.VideoWriter(os.path.join(OUTPUT_PATH, FILE_NAME + \".mp4\"), fourcc, fps, (width, height))\n",
    "\n",
    "keypoints = []\n",
    "frame_idx = 0\n",
    "\n",
    "while True:\n",
    "    success, frame_bgr = cap.read()\n",
    "    if not success:\n",
    "        break\n",
    "    \n",
    "    frame_idx += 1\n",
    "    \n",
    "    frame_rgb  = cv2.cvtColor(frame_bgr, cv2.COLOR_BGR2RGB)\n",
    "    mp_image   = mp.Image(image_format=mp.ImageFormat.SRGB, data=frame_rgb)\n",
    "    timestamp_ms = int(cap.get(cv2.CAP_PROP_POS_MSEC))\n",
    "    result     = detector.detect_for_video(mp_image, timestamp_ms)\n",
    "    if not result.pose_landmarks:\n",
    "        print(f\"No pose landmarks detected in frame {frame_idx}\")\n",
    "        continue\n",
    "\n",
    "    if result.pose_landmarks:\n",
    "        lm = result.pose_landmarks[0]\n",
    "        coords = np.array(\n",
    "            [[l.x, l.y, l.z] for l in lm],\n",
    "            dtype=np.float32\n",
    "        )\n",
    "    else:\n",
    "        coords = np.zeros((len(solutions.pose.PoseLandmark), 3), dtype=np.float32)\n",
    "\n",
    "    keypoints.append(coords)\n",
    "\n",
    "    annotated_rgb = draw_landmarks_on_image(frame_rgb, result)\n",
    "    annotated_bgr = cv2.cvtColor(annotated_rgb, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "    out.write(annotated_bgr)\n",
    "\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "print(f\"Saved annotated video to {os.path.join(OUTPUT_PATH, FILE_NAME + '.mp4')}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4c35d5b",
   "metadata": {},
   "source": [
    "# Phase Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79ca95e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "kp_array = np.stack(keypoints, axis=0)  # shape = (F, L, 3)\n",
    "os.makedirs(os.path.dirname(\"D:/Projects/TrueForm/data/keypoints\"), exist_ok=True)\n",
    "np.save(f\"D:/Projects/TrueForm/data/keypoints/{FILE_NAME}_landmarks.npy\", kp_array)\n",
    "print(f\"Saved landmarks array to {os.path.join('D:/Projects/TrueForm/data/keypoints', f'{FILE_NAME}_landmarks.npy')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dad005f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def angle_between(a, b, c):\n",
    "    ba = a - b\n",
    "    bc = c - b\n",
    "    cos_ang = np.dot(ba, bc) / (np.linalg.norm(ba) * np.linalg.norm(bc))\n",
    "    return math.degrees(math.acos(np.clip(cos_ang, -1.0, 1.0)))\n",
    "\n",
    "landmarks = np.load(f'../data/keypoints/{FILE_NAME}_landmarks.npy')  # shape (F,33,3)\n",
    "F = landmarks.shape[0]\n",
    "\n",
    "# Preallocating arrays for angles\n",
    "left_elbow = np.zeros(F)\n",
    "right_elbow = np.zeros(F)\n",
    "\n",
    "\n",
    "L = solutions.pose.PoseLandmark\n",
    "\n",
    "for i in range(F):\n",
    "    coords = landmarks[i]\n",
    "    left_elbow[i]  = angle_between(\n",
    "        coords[L.LEFT_SHOULDER.value],\n",
    "        coords[L.LEFT_ELBOW.value],\n",
    "        coords[L.LEFT_WRIST.value]\n",
    "    )\n",
    "    right_elbow[i] = angle_between(\n",
    "        coords[L.RIGHT_SHOULDER.value],\n",
    "        coords[L.RIGHT_ELBOW.value],\n",
    "        coords[L.RIGHT_WRIST.value]\n",
    "    )\n",
    "\n",
    "# Plot\n",
    "plt.figure()\n",
    "plt.plot(range(F), left_elbow, label='Left Elbow')\n",
    "plt.plot(range(F), right_elbow, label='Right Elbow')\n",
    "plt.xlabel('Frame #')\n",
    "plt.ylabel('Elbow Angle (°)')\n",
    "plt.title('Elbow Angle Over Time')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af5fd37d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import savgol_filter\n",
    "from scipy.signal import find_peaks\n",
    "\n",
    "\n",
    "window_length = 11  # must be odd, and < len(signal)\n",
    "polyorder     = 2\n",
    "\n",
    "left_smooth  = savgol_filter(left_elbow,  window_length, polyorder)\n",
    "right_smooth = savgol_filter(right_elbow, window_length, polyorder)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(range(F), left_smooth, label='Left Elbow (Smoothed)')\n",
    "plt.plot(range(F), right_smooth, label='Right Elbow (Smoothed)')\n",
    "plt.xlabel('Frame #')\n",
    "plt.ylabel('Elbow Angle (°)')\n",
    "plt.title('Elbow Angle Over Time')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edc26238",
   "metadata": {},
   "outputs": [],
   "source": [
    "peaks, props = find_peaks(right_smooth, height=155, distance=60)\n",
    "# – height=155° ensures we only pick “full-draw” peaks\n",
    "# – distance=30 frames separates shots by at least 1 second (if 30 fps)\n",
    "\n",
    "print(f\"Detected {len(peaks)} shots at frames {peaks}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac09c6f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import savgol_filter, find_peaks\n",
    "\n",
    "# PARAMETERS (tweak)\n",
    "fps = cap.get(cv2.CAP_PROP_FPS) or 30.0\n",
    "min_shot_sep_s = 0.7               # minimum seconds between shots (0.7s default)\n",
    "min_prominence = 8.0               # degrees (or signal units) that a peak must stand out by\n",
    "min_width_frames = int(0.05 * fps) # minimal width of peak in frames (e.g., 50 ms)\n",
    "min_hold_frames = int(0.08 * fps)  # require short hold (~80 ms) — tune as needed\n",
    "\n",
    "# right_smooth is your primary signal (e.g., smoothed elbow angle/time series)\n",
    "# 1) smooth more reliably with Savitzky-Golay\n",
    "win = 7 if len(right_smooth) > 7 else (len(right_smooth) // 2 * 2 + 1)\n",
    "right_sg = savgol_filter(right_smooth, window_length=win, polyorder=2)\n",
    "\n",
    "# 2) adaptive height baseline: require peaks above e.g. 80th percentile (optional)\n",
    "height_threshold = np.percentile(right_sg, 80)\n",
    "\n",
    "# 3) find candidate peaks using prominence + width + distance (in frames)\n",
    "peaks, props = find_peaks(\n",
    "    right_sg,\n",
    "    prominence=min_prominence,\n",
    "    width=min_width_frames,\n",
    "    distance=int(min_shot_sep_s * fps),\n",
    "    height=height_threshold\n",
    ")\n",
    "\n",
    "# 4) optional extra validation using wrist velocity and hold stability\n",
    "# compute wrist angle or wrist position speed (example: left wrist y-velocity)\n",
    "# assume wrist_y is an array of normalized y positions per frame\n",
    "wrist_y = landmarks[:, L.RIGHT_WRIST.value, 1]  # normalized Y (replace if needed)\n",
    "wrist_speed = np.abs(np.gradient(wrist_y)) * fps    # approx px/sec in normalized units\n",
    "\n",
    "valid_peaks = []\n",
    "for pk in peaks:\n",
    "    # require a brief low-velocity \"hold\" before the peak\n",
    "    hold_start = max(0, pk - min_hold_frames)\n",
    "    hold_window_speed = np.nanmean(wrist_speed[hold_start:pk]) if pk>hold_start else np.inf\n",
    "\n",
    "    # require a release spike after the peak (jerk): mean speed in small window after peak should be larger\n",
    "    post_window = wrist_speed[pk: min(len(wrist_speed), pk + int(0.12*fps))]\n",
    "    post_mean = np.nanmean(post_window) if len(post_window)>0 else 0.0\n",
    "\n",
    "    # heuristic conditions\n",
    "    if hold_window_speed < 0.01 and post_mean > 0.02:\n",
    "        valid_peaks.append(pk)\n",
    "    else:\n",
    "        # weaker fallback: accept if the peak has strong prominence/width\n",
    "        if props['prominences'][np.where(peaks==pk)[0][0]] > (min_prominence * 1.5):\n",
    "            valid_peaks.append(pk)\n",
    "\n",
    "# final peaks\n",
    "peaks = np.array(valid_peaks, dtype=int)\n",
    "print(f\"Detected {len(peaks)} shots at frames {peaks}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0136f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "shot_metrics = []\n",
    "for p in peaks:\n",
    "    # find where this draw started (local trough before p)\n",
    "    start = np.argmin(left_smooth[max(0, p-50):p]) + max(0, p-50)\n",
    "    peak_angle = left_smooth[p]\n",
    "    hold_var   = np.std(left_smooth[p-10:p])\n",
    "    pull_rate  = (peak_angle - left_smooth[start]) / (p - start)\n",
    "    shot_metrics.append({\n",
    "        \"frame_start\": start,\n",
    "        \"frame_peak\" : p,\n",
    "        \"peak_angle\" : peak_angle,\n",
    "        \"hold_variance\": hold_var,\n",
    "        \"pull_rate\": pull_rate,\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53c8fc0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "shot_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f0b2cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# --- 1) Build DataFrame from your list of dicts:\n",
    "df = pd.DataFrame(shot_metrics)\n",
    "df.index.name = \"shot_idx\"\n",
    "\n",
    "# --- 2) Add right-arm peak angle & symmetry difference:\n",
    "# (we’ll assume the same peak frames correspond on right side)\n",
    "df['peak_angle_R'] = right_smooth[df['frame_peak']]\n",
    "df['symmetry_diff'] = (df['peak_angle'] - df['peak_angle_R']).abs()\n",
    "\n",
    "# --- 3) Shot duration (frames → seconds):\n",
    "df['duration_s'] = (df['frame_peak'] - df['frame_start']) / fps\n",
    "\n",
    "# --- 4) Consistency score (higher = steadier hold):\n",
    "# simple example: 1 / (1 + hold_variance)\n",
    "df['consistency_score'] = 1.0 / (1.0 + df['hold_variance'])\n",
    "\n",
    "# Quick look:\n",
    "print(df[['frame_start','frame_peak',\n",
    "          'peak_angle','peak_angle_R','symmetry_diff',\n",
    "          'hold_variance','pull_rate','duration_s','consistency_score']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4358e3e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dist(a, b):\n",
    "    return np.linalg.norm(a - b)\n",
    "\n",
    "# for each shot, measure ankle‐to‐ankle distance at the peak frame\n",
    "stance_widths = []\n",
    "for _, row in df.iterrows():\n",
    "    coords = landmarks[int(row['frame_peak'])]\n",
    "    lw = coords[L.LEFT_ANKLE.value]\n",
    "    rw = coords[L.RIGHT_ANKLE.value]\n",
    "    stance_widths.append(dist(lw, rw))\n",
    "\n",
    "df['stance_width'] = stance_widths\n",
    "\n",
    "# View updated table\n",
    "print(df[['peak_angle','symmetry_diff','stance_width']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcef8079",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(f'../data/metrics/{FILE_NAME}_shot_metrics.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb9c4795",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from mediapipe import solutions\n",
    "\n",
    "# Paths (adjust if needed)\n",
    "LANDMARKS_PATH = f'../data/keypoints/{FILE_NAME}_landmarks.npy'\n",
    "METRICS_PATH   = f'../data/metrics/{FILE_NAME}_shot_metrics.csv'\n",
    "\n",
    "# Load data\n",
    "landmarks = np.load(LANDMARKS_PATH)  # shape = (F,33,3)\n",
    "df        = pd.read_csv(METRICS_PATH, index_col='shot_idx')\n",
    "\n",
    "# Map PoseLandmark enum and connections\n",
    "L = solutions.pose.PoseLandmark\n",
    "connections = solutions.pose.POSE_CONNECTIONS\n",
    "\n",
    "# Choose the shot index to visualize (e.g. shot_idx = 1)\n",
    "shot_idx   = 1\n",
    "shot       = df.loc[shot_idx]\n",
    "frame_peak = int(shot['frame_peak'])\n",
    "coords     = landmarks[frame_peak]    # (33, 3) array\n",
    "\n",
    "# Build a per‐landmark color array\n",
    "colors = []\n",
    "for lm_idx in range(coords.shape[0]):\n",
    "    if lm_idx in (L.LEFT_ELBOW.value, L.RIGHT_ELBOW.value):\n",
    "        # if symmetry difference is above your threshold, paint red\n",
    "        colors.append('red' if shot['symmetry_diff'] > 5.0 else 'green')\n",
    "    else:\n",
    "        colors.append('green')\n",
    "\n",
    "# Plot the skeleton\n",
    "fig = plt.figure(figsize=(8,6))\n",
    "ax  = fig.add_subplot(111, projection='3d')\n",
    "ax.set_title(f'Shot {shot_idx} Peak Pose (Frame {frame_peak})')\n",
    "\n",
    "# Scatter plot of all landmarks\n",
    "ax.scatter(coords[:,0], coords[:,1], coords[:,2], c=colors, s=40)\n",
    "\n",
    "# Draw the bones\n",
    "for start, end in connections:\n",
    "    a = coords[start]  # no .value\n",
    "    b = coords[end]\n",
    "    ax.plot([a[0], b[0]],\n",
    "            [a[1], b[1]],\n",
    "            [a[2], b[2]],\n",
    "            c='gray', lw=2)\n",
    "\n",
    "# Axes labels\n",
    "ax.set_xlabel('X (norm)')\n",
    "ax.set_ylabel('Y (norm)')\n",
    "ax.set_zlabel('Z (norm)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89aac708",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "from mediapipe import solutions\n",
    "\n",
    "# ---------- CONFIG ----------\n",
    "\n",
    "LANDMARKS_PATH  = f\"../data/keypoints/{FILE_NAME}_landmarks.npy\"\n",
    "METRICS_PATH    = f\"../data/metrics/{FILE_NAME}_shot_metrics.csv\"\n",
    "OUTPUT_PATH     = f\"../data/processed/{FILE_NAME}_with_corrections.mp4\"\n",
    "\n",
    "# Numeric thresholds (tune these)\n",
    "TH_SYMMETRY_DEG = 5.0     # degrees: peak left/right elbow difference\n",
    "TH_HOLD_VAR     = 2.0     # degrees: stddev of hold angle\n",
    "TH_STANCE_RATIO_MIN = 0.8 # stance_width / shoulder_span < -> too narrow\n",
    "TH_STANCE_RATIO_MAX = 1.5 # > -> too wide\n",
    "TH_RELEASE_JERK = 10.0    # degrees/frame: big change right after release\n",
    "HOLD_WINDOW_FRAMES = 10   # frames before peak considered \"hold\"\n",
    "\n",
    "# ---------- helpers ----------\n",
    "L = solutions.pose.PoseLandmark\n",
    "\n",
    "def dist(a, b):\n",
    "    return np.linalg.norm(a - b)\n",
    "\n",
    "def angle_between(a, b, c):\n",
    "    ba = a - b\n",
    "    bc = c - b\n",
    "    denom = (np.linalg.norm(ba) * np.linalg.norm(bc))\n",
    "    if denom == 0:\n",
    "        return 0.0\n",
    "    cosang = np.dot(ba, bc) / denom\n",
    "    return math.degrees(math.acos(np.clip(cosang, -1.0, 1.0)))\n",
    "\n",
    "def normalized_to_pixel(norm_pt, width, height):\n",
    "    # norm_pt is (x,y,z)\n",
    "    return int(norm_pt[0] * width), int(norm_pt[1] * height)\n",
    "\n",
    "def draw_text_box(img, text_lines, origin=(10,30), font_scale=0.45, thickness=1, max_width_ratio=0.45):\n",
    "    \"\"\"\n",
    "    Draws a semi-transparent text box with word wrapping and optional small font size.\n",
    "    \n",
    "    Args:\n",
    "        img: The image frame.\n",
    "        text_lines: List of suggestion strings.\n",
    "        origin: Top-left corner of the box (x, y).\n",
    "        font_scale: Fixed font size (set small, e.g., 0.45).\n",
    "        thickness: Text thickness.\n",
    "        max_width_ratio: Max width of the text box relative to frame width.\n",
    "    \"\"\"\n",
    "    x0, y0 = origin\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    max_width_px = int(img.shape[1] * max_width_ratio)\n",
    "\n",
    "    wrapped_lines = []\n",
    "    for line in text_lines:\n",
    "        words = line.split(\" \")\n",
    "        current_line = \"\"\n",
    "        for word in words:\n",
    "            test_line = (current_line + \" \" + word).strip()\n",
    "            (tw, th), _ = cv2.getTextSize(test_line, font, font_scale, thickness)\n",
    "            if tw <= max_width_px:\n",
    "                current_line = test_line\n",
    "            else:\n",
    "                wrapped_lines.append(current_line)\n",
    "                current_line = word\n",
    "        if current_line:\n",
    "            wrapped_lines.append(current_line)\n",
    "\n",
    "    # Compute box size\n",
    "    w = 0\n",
    "    h = 0\n",
    "    for line in wrapped_lines:\n",
    "        (tw, th), _ = cv2.getTextSize(line, font, font_scale, thickness)\n",
    "        w = max(w, tw)\n",
    "        h += th + 6\n",
    "\n",
    "    # Background rectangle\n",
    "    cv2.rectangle(img, (x0-6, y0-16), (x0+w+6, y0 + h), (0,0,0), -1)\n",
    "\n",
    "    # Put text\n",
    "    y = y0\n",
    "    for line in wrapped_lines:\n",
    "        cv2.putText(img, line, (x0, y), font, font_scale, (255,255,255), thickness, cv2.LINE_AA)\n",
    "        (tw, th), _ = cv2.getTextSize(line, font, font_scale, thickness)\n",
    "        y += th + 6\n",
    "\n",
    "\n",
    "# ---------- load data ----------\n",
    "landmarks_all = np.load(LANDMARKS_PATH)  # shape (F, 33, 3)\n",
    "df = pd.read_csv(METRICS_PATH, index_col='shot_idx')\n",
    "cap = cv2.VideoCapture(FILE_PATH)\n",
    "if not cap.isOpened():\n",
    "    raise RuntimeError(\"Can't open video.\")\n",
    "\n",
    "fps = cap.get(cv2.CAP_PROP_FPS) or 30.0\n",
    "W = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "H = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "out = cv2.VideoWriter(OUTPUT_PATH, fourcc, fps, (W, H))\n",
    "\n",
    "# Precompute some per-shot diagnostics (more could be added)\n",
    "diagnostics = {}  # shot_idx -> dict\n",
    "\n",
    "for shot_idx, row in df.iterrows():\n",
    "    peak = int(row['frame_peak'])\n",
    "    start = int(row['frame_start'])\n",
    "    # shoulder span at peak (normalized)\n",
    "    coords_peak = landmarks_all[peak]\n",
    "    shoulder_span = dist(coords_peak[L.LEFT_SHOULDER.value], coords_peak[L.RIGHT_SHOULDER.value])\n",
    "    # stance width already in df (assumed normalized)\n",
    "    stance_w = row.get('stance_width', None)\n",
    "    stance_ratio = None\n",
    "    if stance_w is not None and shoulder_span > 0:\n",
    "        stance_ratio = stance_w / shoulder_span\n",
    "\n",
    "    # hold variance and symmetry already present in df\n",
    "    hold_var = row.get('hold_variance', 0.0)\n",
    "    symmetry = row.get('symmetry_diff', 0.0)\n",
    "\n",
    "    # Release jerk: compute change in elbow angle immediately after peak\n",
    "    # use left elbow angle time series approximated from landmarks\n",
    "    # we'll compute left elbow angle for frames [peak, peak+3]\n",
    "    left_angles = []\n",
    "    for f in range(peak, min(peak+4, landmarks_all.shape[0])):\n",
    "        c = landmarks_all[f]\n",
    "        a = angle_between(c[L.LEFT_SHOULDER.value], c[L.LEFT_ELBOW.value], c[L.LEFT_WRIST.value])\n",
    "        left_angles.append(a)\n",
    "    release_jerk = 0.0\n",
    "    if len(left_angles) >= 2:\n",
    "        release_jerk = max(abs(left_angles[i+1] - left_angles[i]) for i in range(len(left_angles)-1))\n",
    "    # head stability: stddev of nose during hold window\n",
    "    hold_start = max(start, peak - HOLD_WINDOW_FRAMES)\n",
    "    nose_positions = landmarks_all[hold_start:peak, L.NOSE.value] if peak > hold_start else np.array([])\n",
    "    head_std = 0.0\n",
    "    if len(nose_positions) > 0:\n",
    "        # compute pixel variance in y as proxy for vertical stability\n",
    "        head_std = float(np.std(nose_positions[:,1]))\n",
    "\n",
    "    diagnostics[shot_idx] = {\n",
    "        \"shoulder_span\": shoulder_span,\n",
    "        \"stance_w\": stance_w,\n",
    "        \"stance_ratio\": stance_ratio,\n",
    "        \"hold_var\": float(hold_var),\n",
    "        \"symmetry\": float(symmetry),\n",
    "        \"release_jerk\": float(release_jerk),\n",
    "        \"head_std\": float(head_std),\n",
    "        \"frame_start\": start,\n",
    "        \"frame_peak\": peak\n",
    "    }\n",
    "\n",
    "# ---------- main overlay loop ----------\n",
    "frame_idx = 0\n",
    "# Build shot lookup by frame range for quick per-frame shot mapping\n",
    "shots_by_frame = {}\n",
    "for shot_idx, diag in diagnostics.items():\n",
    "    s = int(diag['frame_start'])\n",
    "    p = int(diag['frame_peak'])\n",
    "    # annotate from start to (peak + 10) frames to include release\n",
    "    end = min(p + 10, landmarks_all.shape[0]-1)\n",
    "    for f in range(s, end+1):\n",
    "        shots_by_frame[f] = shot_idx\n",
    "\n",
    "cap.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    h, w = frame.shape[:2]\n",
    "    annotated = frame.copy()\n",
    "\n",
    "    if frame_idx < len(landmarks_all):\n",
    "        lm_norm = landmarks_all[frame_idx]  # (33,3)\n",
    "    else:\n",
    "        lm_norm = None\n",
    "\n",
    "    if frame_idx in shots_by_frame and lm_norm is not None:\n",
    "        shot_idx = shots_by_frame[frame_idx]\n",
    "        diag = diagnostics[shot_idx]\n",
    "        s = diag['frame_start']\n",
    "        p = diag['frame_peak']\n",
    "\n",
    "        # compute suggestion list\n",
    "        suggestions = []\n",
    "        bad_joints = []\n",
    "\n",
    "        if diag['symmetry'] > TH_SYMMETRY_DEG:\n",
    "            suggestions.append(f\"Asymmetric draw: {diag['symmetry']:.1f} degrees between arms\")\n",
    "            bad_joints += [L.LEFT_ELBOW.value, L.RIGHT_ELBOW.value]\n",
    "        if diag['hold_var'] > TH_HOLD_VAR:\n",
    "            suggestions.append(\"Unstable anchor: hold variance high\")\n",
    "            bad_joints += [L.LEFT_WRIST.value, L.RIGHT_WRIST.value]\n",
    "        if diag['stance_ratio'] is not None:\n",
    "            if diag['stance_ratio'] < TH_STANCE_RATIO_MIN:\n",
    "                suggestions.append(\"Stance too narrow: widen feet\")\n",
    "                bad_joints += [L.LEFT_ANKLE.value, L.RIGHT_ANKLE.value]\n",
    "            elif diag['stance_ratio'] > TH_STANCE_RATIO_MAX:\n",
    "                suggestions.append(\"Stance too wide: bring feet closer\")\n",
    "                bad_joints += [L.LEFT_ANKLE.value, L.RIGHT_ANKLE.value]\n",
    "        if diag['release_jerk'] > TH_RELEASE_JERK:\n",
    "            suggestions.append(\"Jerky release detected: work on smooth follow-through\")\n",
    "            bad_joints += [L.LEFT_WRIST.value]\n",
    "        if diag['head_std'] > 0.02:  # normalized pos variance threshold (tune)\n",
    "            suggestions.append(\"Head movement high during hold: stabilize head\")\n",
    "            bad_joints += [L.NOSE.value]\n",
    "\n",
    "        if len(suggestions) == 0:\n",
    "            suggestions = [\"No major issues detected — good draw!\"]\n",
    "\n",
    "        # Draw landmarks + flag joints\n",
    "        # convert normalized to pixels\n",
    "        pix = {}\n",
    "        for i in range(lm_norm.shape[0]):\n",
    "            x_px = int(lm_norm[i,0] * w)\n",
    "            y_px = int(lm_norm[i,1] * h)\n",
    "            pix[i] = (x_px, y_px)\n",
    "        # draw bones (use media pipe connections but they are ints)\n",
    "        for a,b in solutions.pose.POSE_CONNECTIONS:\n",
    "            # a,b may be ints or pairs; treat as ints\n",
    "            pa = pix[int(a)]\n",
    "            pb = pix[int(b)]\n",
    "            cv2.line(annotated, pa, pb, (180,180,180), 2)\n",
    "\n",
    "        # draw joints: red if in bad_joints else green\n",
    "        for i, (x,y) in pix.items():\n",
    "            color = (0,255,0) if i not in bad_joints else (0,0,255)\n",
    "            cv2.circle(annotated, (x,y), 6, color, -1)\n",
    "            # annotate left/right shoulders for orientation clarity\n",
    "            if i in (L.LEFT_SHOULDER.value, L.RIGHT_SHOULDER.value):\n",
    "                cv2.putText(annotated, 'L-S' if i==L.LEFT_SHOULDER.value else 'R-S',\n",
    "                            (x+6, y-6), cv2.FONT_HERSHEY_SIMPLEX, 0.4, (220,220,220), 1, cv2.LINE_AA)\n",
    "\n",
    "        # Draw an arrow showing target direction (optional): use vector from hips to nose as rough facing\n",
    "        hip_mid = ((lm_norm[L.LEFT_HIP.value] + lm_norm[L.RIGHT_HIP.value]) / 2.0)\n",
    "        nose = lm_norm[L.NOSE.value]\n",
    "        hip_px = normalized_to_pixel(hip_mid, w, h)\n",
    "        nose_px = normalized_to_pixel(nose, w, h)\n",
    "        cv2.arrowedLine(annotated, hip_px, nose_px, (255,200,0), 2, tipLength=0.15)\n",
    "\n",
    "        # Put suggestions text box\n",
    "        draw_text_box(annotated, suggestions, origin=(10,30))\n",
    "\n",
    "        # Draw shot label/metadata\n",
    "        cv2.putText(annotated, f\"Shot {shot_idx} Frame {frame_idx}\", (10, H-20),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255,255,255), 2, cv2.LINE_AA)\n",
    "\n",
    "    # Optionally draw frame index\n",
    "    cv2.putText(annotated, f\"Frame {frame_idx}\", (W-160, 20),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255,255,255), 1, cv2.LINE_AA)\n",
    "\n",
    "    out.write(annotated)\n",
    "    frame_idx += 1\n",
    "\n",
    "cap.release()\n",
    "out.release()\n",
    "print(\"Saved annotated video to:\", OUTPUT_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd3583e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "from mediapipe import solutions\n",
    "\n",
    "# ---------- CONFIG ----------\n",
    "\n",
    "LANDMARKS_PATH  = f\"../data/keypoints/{FILE_NAME}_landmarks.npy\"\n",
    "METRICS_PATH    = f\"../data/metrics/{FILE_NAME}_shot_metrics.csv\"\n",
    "OUTPUT_PATH     = f\"../data/processed/{FILE_NAME}_with_corrections.mp4\"\n",
    "\n",
    "# Numeric thresholds (tune these)\n",
    "TH_SYMMETRY_DEG = 5.0     # degrees: peak left/right elbow difference\n",
    "TH_HOLD_VAR     = 2.0     # degrees: stddev of hold angle\n",
    "TH_STANCE_RATIO_MIN = 0.8 # stance_width / shoulder_span < -> too narrow\n",
    "TH_STANCE_RATIO_MAX = 1.5 # > -> too wide\n",
    "TH_RELEASE_JERK = 10.0    # degrees/frame: big change right after release\n",
    "HOLD_WINDOW_FRAMES = 10   # frames before peak considered \"hold\"\n",
    "\n",
    "# ---------- helpers ----------\n",
    "L = solutions.pose.PoseLandmark\n",
    "\n",
    "def dist(a, b):\n",
    "    return np.linalg.norm(a - b)\n",
    "\n",
    "def angle_between(a, b, c):\n",
    "    ba = a - b\n",
    "    bc = c - b\n",
    "    denom = (np.linalg.norm(ba) * np.linalg.norm(bc))\n",
    "    if denom == 0:\n",
    "        return 0.0\n",
    "    cosang = np.dot(ba, bc) / denom\n",
    "    return math.degrees(math.acos(np.clip(cosang, -1.0, 1.0)))\n",
    "\n",
    "def normalized_to_pixel(norm_pt, width, height):\n",
    "    # norm_pt is (x,y,z)\n",
    "    return int(norm_pt[0] * width), int(norm_pt[1] * height)\n",
    "\n",
    "def draw_text_box(img, text_lines, origin=(10,30), font_scale=0.45, thickness=1, max_width_ratio=0.45):\n",
    "    \"\"\"\n",
    "    Draws a semi-transparent text box with word wrapping and optional small font size.\n",
    "    \"\"\"\n",
    "    x0, y0 = origin\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    max_width_px = int(img.shape[1] * max_width_ratio)\n",
    "\n",
    "    wrapped_lines = []\n",
    "    for line in text_lines:\n",
    "        words = line.split(\" \")\n",
    "        current_line = \"\"\n",
    "        for word in words:\n",
    "            test_line = (current_line + \" \" + word).strip()\n",
    "            (tw, th), _ = cv2.getTextSize(test_line, font, font_scale, thickness)\n",
    "            if tw <= max_width_px:\n",
    "                current_line = test_line\n",
    "            else:\n",
    "                wrapped_lines.append(current_line)\n",
    "                current_line = word\n",
    "        if current_line:\n",
    "            wrapped_lines.append(current_line)\n",
    "\n",
    "    # Compute box size\n",
    "    w = 0\n",
    "    h = 0\n",
    "    for line in wrapped_lines:\n",
    "        (tw, th), _ = cv2.getTextSize(line, font, font_scale, thickness)\n",
    "        w = max(w, tw)\n",
    "        h += th + 6\n",
    "\n",
    "    # Background rectangle\n",
    "    cv2.rectangle(img, (x0-6, y0-16), (x0+w+6, y0 + h), (0,0,0), -1)\n",
    "\n",
    "    # Put text\n",
    "    y = y0\n",
    "    for line in wrapped_lines:\n",
    "        cv2.putText(img, line, (x0, y), font, font_scale, (255,255,255), thickness, cv2.LINE_AA)\n",
    "        (tw, th), _ = cv2.getTextSize(line, font, font_scale, thickness)\n",
    "        y += th + 6\n",
    "\n",
    "\n",
    "# ---------- load data ----------\n",
    "landmarks_all = np.load(LANDMARKS_PATH)  # shape (F, 33, 3)\n",
    "df = pd.read_csv(METRICS_PATH, index_col='shot_idx')\n",
    "cap = cv2.VideoCapture(FILE_PATH)\n",
    "if not cap.isOpened():\n",
    "    raise RuntimeError(\"Can't open video.\")\n",
    "\n",
    "fps = cap.get(cv2.CAP_PROP_FPS) or 30.0\n",
    "W = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "H = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "out = cv2.VideoWriter(OUTPUT_PATH, fourcc, fps, (W, H))\n",
    "\n",
    "# Precompute some per-shot diagnostics (more could be added)\n",
    "diagnostics = {}  # shot_idx -> dict\n",
    "\n",
    "for shot_idx, row in df.iterrows():\n",
    "    peak = int(row['frame_peak'])\n",
    "    start = int(row['frame_start'])\n",
    "    # shoulder span at peak (normalized)\n",
    "    coords_peak = landmarks_all[peak]\n",
    "    shoulder_span = dist(coords_peak[L.LEFT_SHOULDER.value], coords_peak[L.RIGHT_SHOULDER.value])\n",
    "    # stance width already in df (assumed normalized)\n",
    "    stance_w = row.get('stance_width', None)\n",
    "    stance_ratio = None\n",
    "    if stance_w is not None and shoulder_span > 0:\n",
    "        stance_ratio = stance_w / shoulder_span\n",
    "\n",
    "    # hold variance and symmetry already present in df\n",
    "    hold_var = row.get('hold_variance', 0.0)\n",
    "    symmetry = row.get('symmetry_diff', 0.0)\n",
    "\n",
    "    # Release jerk: compute change in elbow angle immediately after peak\n",
    "    left_angles = []\n",
    "    for f in range(peak, min(peak+4, landmarks_all.shape[0])):\n",
    "        c = landmarks_all[f]\n",
    "        a = angle_between(c[L.LEFT_SHOULDER.value], c[L.LEFT_ELBOW.value], c[L.LEFT_WRIST.value])\n",
    "        left_angles.append(a)\n",
    "    release_jerk = 0.0\n",
    "    if len(left_angles) >= 2:\n",
    "        release_jerk = max(abs(left_angles[i+1] - left_angles[i]) for i in range(len(left_angles)-1))\n",
    "    # head stability: stddev of nose during hold window\n",
    "    hold_start = max(start, peak - HOLD_WINDOW_FRAMES)\n",
    "    nose_positions = landmarks_all[hold_start:peak, L.NOSE.value] if peak > hold_start else np.array([])\n",
    "    head_std = 0.0\n",
    "    if len(nose_positions) > 0:\n",
    "        # compute pixel variance in y as proxy for vertical stability\n",
    "        head_std = float(np.std(nose_positions[:,1]))\n",
    "\n",
    "    diagnostics[shot_idx] = {\n",
    "        \"shoulder_span\": shoulder_span,\n",
    "        \"stance_w\": stance_w,\n",
    "        \"stance_ratio\": stance_ratio,\n",
    "        \"hold_var\": float(hold_var),\n",
    "        \"symmetry\": float(symmetry),\n",
    "        \"release_jerk\": float(release_jerk),\n",
    "        \"head_std\": float(head_std),\n",
    "        \"frame_start\": start,\n",
    "        \"frame_peak\": peak\n",
    "    }\n",
    "\n",
    "# ---------- main overlay loop ----------\n",
    "frame_idx = 0\n",
    "# Build shot lookup by frame range for quick per-frame shot mapping\n",
    "shots_by_frame = {}\n",
    "for shot_idx, diag in diagnostics.items():\n",
    "    s = int(diag['frame_start'])\n",
    "    p = int(diag['frame_peak'])\n",
    "    # annotate from start to (peak + 10) frames to include release\n",
    "    end = min(p + 10, landmarks_all.shape[0]-1)\n",
    "    for f in range(s, end+1):\n",
    "        shots_by_frame[f] = shot_idx\n",
    "\n",
    "cap.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    h, w = frame.shape[:2]\n",
    "    annotated = frame.copy()\n",
    "\n",
    "    if frame_idx < len(landmarks_all):\n",
    "        lm_norm = landmarks_all[frame_idx]  # (33,3)\n",
    "    else:\n",
    "        lm_norm = None\n",
    "\n",
    "    pix = {}\n",
    "    if lm_norm is not None:\n",
    "        # convert normalized to pixels for all landmarks (used for drawing always)\n",
    "        for i in range(lm_norm.shape[0]):\n",
    "            x_px = int(lm_norm[i,0] * w)\n",
    "            y_px = int(lm_norm[i,1] * h)\n",
    "            pix[i] = (x_px, y_px)\n",
    "\n",
    "        # DRAW SKELETON (always visible when landmarks exist)\n",
    "        # bones in neutral gray\n",
    "        for a, b in solutions.pose.POSE_CONNECTIONS:\n",
    "            pa = pix[int(a)]\n",
    "            pb = pix[int(b)]\n",
    "            cv2.line(annotated, pa, pb, (180, 180, 180), 2)\n",
    "\n",
    "        # default joint color (neutral)\n",
    "        for i, (x, y) in pix.items():\n",
    "            cv2.circle(annotated, (x, y), 5, (200, 200, 200), -1)\n",
    "\n",
    "        # annotate left/right shoulders for orientation clarity (always visible)\n",
    "        for i in (L.LEFT_SHOULDER.value, L.RIGHT_SHOULDER.value):\n",
    "            if i in pix:\n",
    "                x, y = pix[i]\n",
    "                cv2.putText(annotated, 'L-S' if i==L.LEFT_SHOULDER.value else 'R-S',\n",
    "                            (x+6, y-6), cv2.FONT_HERSHEY_SIMPLEX, 0.4, (220,220,220), 1, cv2.LINE_AA)\n",
    "\n",
    "        # Draw an arrow showing target direction (optional): use vector from hips to nose as rough facing\n",
    "        hip_mid = ((lm_norm[L.LEFT_HIP.value] + lm_norm[L.RIGHT_HIP.value]) / 2.0)\n",
    "        nose = lm_norm[L.NOSE.value]\n",
    "        hip_px = normalized_to_pixel(hip_mid, w, h)\n",
    "        nose_px = normalized_to_pixel(nose, w, h)\n",
    "        cv2.arrowedLine(annotated, hip_px, nose_px, (255,200,0), 2, tipLength=0.15)\n",
    "\n",
    "    # If this frame is within a shot, overlay suggestions and highlight bad joints\n",
    "    if frame_idx in shots_by_frame and lm_norm is not None:\n",
    "        shot_idx = shots_by_frame[frame_idx]\n",
    "        diag = diagnostics[shot_idx]\n",
    "        s = diag['frame_start']\n",
    "        p = diag['frame_peak']\n",
    "\n",
    "        # compute suggestion list\n",
    "        suggestions = []\n",
    "        bad_joints = []\n",
    "\n",
    "        if diag['symmetry'] > TH_SYMMETRY_DEG:\n",
    "            suggestions.append(f\"Asymmetric draw: {diag['symmetry']:.1f} degrees between arms\")\n",
    "            bad_joints += [L.LEFT_ELBOW.value, L.RIGHT_ELBOW.value]\n",
    "        if diag['hold_var'] > TH_HOLD_VAR:\n",
    "            suggestions.append(\"Unstable anchor: hold variance high\")\n",
    "            bad_joints += [L.LEFT_WRIST.value, L.RIGHT_WRIST.value]\n",
    "        if diag['stance_ratio'] is not None:\n",
    "            if diag['stance_ratio'] < TH_STANCE_RATIO_MIN:\n",
    "                suggestions.append(\"Stance too narrow: widen feet\")\n",
    "                bad_joints += [L.LEFT_ANKLE.value, L.RIGHT_ANKLE.value]\n",
    "            elif diag['stance_ratio'] > TH_STANCE_RATIO_MAX:\n",
    "                suggestions.append(\"Stance too wide: bring feet closer\")\n",
    "                bad_joints += [L.LEFT_ANKLE.value, L.RIGHT_ANKLE.value]\n",
    "        if diag['release_jerk'] > TH_RELEASE_JERK:\n",
    "            suggestions.append(\"Jerky release detected: work on smooth follow-through\")\n",
    "            bad_joints += [L.LEFT_WRIST.value]\n",
    "        if diag['head_std'] > 0.02:  # normalized pos variance threshold (tune)\n",
    "            suggestions.append(\"Head movement high during hold: stabilize head\")\n",
    "            bad_joints += [L.NOSE.value]\n",
    "\n",
    "        if len(suggestions) == 0:\n",
    "            suggestions = [\"No major issues detected — good draw!\"]\n",
    "\n",
    "        # Re-draw joints with shot-specific coloring (green by default, red for bad joints)\n",
    "        for i, (x, y) in pix.items():\n",
    "            color = (0,255,0) if i not in bad_joints else (0,0,255)\n",
    "            cv2.circle(annotated, (x,y), 6, color, -1)\n",
    "\n",
    "        # Overwrite bones with a slightly brighter color so shot frames stand out\n",
    "        for a, b in solutions.pose.POSE_CONNECTIONS:\n",
    "            pa = pix[int(a)]\n",
    "            pb = pix[int(b)]\n",
    "            cv2.line(annotated, pa, pb, (200,200,200), 2)\n",
    "\n",
    "        # Put suggestions text box\n",
    "        draw_text_box(annotated, suggestions, origin=(10,30))\n",
    "\n",
    "        # Draw shot label/metadata\n",
    "        cv2.putText(annotated, f\"Shot {shot_idx} Frame {frame_idx}\", (10, H-20),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255,255,255), 2, cv2.LINE_AA)\n",
    "\n",
    "    # Optionally draw frame index\n",
    "    cv2.putText(annotated, f\"Frame {frame_idx}\", (W-160, 20),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255,255,255), 1, cv2.LINE_AA)\n",
    "\n",
    "    out.write(annotated)\n",
    "    frame_idx += 1\n",
    "\n",
    "cap.release()\n",
    "out.release()\n",
    "print(\"Saved annotated video to:\", OUTPUT_PATH)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d64a3d54",
   "metadata": {},
   "source": [
    "### Suggestion Always Visible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f15eeb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "from collections import deque\n",
    "from mediapipe import solutions\n",
    "\n",
    "\n",
    "LANDMARKS_PATH  = f\"../data/keypoints/{FILE_NAME}_landmarks.npy\"\n",
    "METRICS_PATH    = f\"../data/metrics/{FILE_NAME}_shot_metrics.csv\"\n",
    "OUTPUT_PATH     = f\"../data/processed/{FILE_NAME}_with_corrections_new.mp4\"\n",
    "\n",
    "# Numeric thresholds (tune these)\n",
    "TH_SYMMETRY_DEG = 5.0     # degrees: peak left/right elbow difference\n",
    "TH_HOLD_VAR     = 2.0     # degrees: stddev of hold angle\n",
    "TH_STANCE_RATIO_MIN = 0.8 # stance_width / shoulder_span < -> too narrow\n",
    "TH_STANCE_RATIO_MAX = 1.5 # > -> too wide\n",
    "TH_RELEASE_JERK = 10.0    # degrees/frame: big change right after release\n",
    "HOLD_WINDOW_FRAMES = 10   # frames before peak considered \"hold\"\n",
    "\n",
    "# Convenience alias for landmarks\n",
    "L = solutions.pose.PoseLandmark\n",
    "\n",
    "# ---------------- helpers ----------------\n",
    "def dist(a, b):\n",
    "    \"\"\"Euclidean distance between two 3D points (handles NaNs).\"\"\"\n",
    "    if a is None or b is None:\n",
    "        return 0.0\n",
    "    a = np.asarray(a)\n",
    "    b = np.asarray(b)\n",
    "    if np.any(np.isnan(a)) or np.any(np.isnan(b)):\n",
    "        return 0.0\n",
    "    return float(np.linalg.norm(a - b))\n",
    "\n",
    "def angle_between(a, b, c):\n",
    "    \"\"\"\n",
    "    Angle at point b between ba and bc in degrees.\n",
    "    Returns 0.0 if any points are invalid or the denominator is zero.\n",
    "    \"\"\"\n",
    "    a = np.asarray(a)\n",
    "    b = np.asarray(b)\n",
    "    c = np.asarray(c)\n",
    "    if np.any(np.isnan(a)) or np.any(np.isnan(b)) or np.any(np.isnan(c)):\n",
    "        return 0.0\n",
    "    ba = a - b\n",
    "    bc = c - b\n",
    "    na = np.linalg.norm(ba)\n",
    "    nb = np.linalg.norm(bc)\n",
    "    denom = na * nb\n",
    "    if denom == 0:\n",
    "        return 0.0\n",
    "    cosang = np.dot(ba, bc) / denom\n",
    "    cosang = np.clip(cosang, -1.0, 1.0)\n",
    "    return math.degrees(math.acos(cosang))\n",
    "\n",
    "def normalized_to_pixel(norm_pt, width, height):\n",
    "    \"\"\"\n",
    "    Convert normalized (x,y,...) in [0,1] to pixel coords, clamp inside image.\n",
    "    Returns tuple (x_px, y_px) as ints.\n",
    "    \"\"\"\n",
    "    nx, ny = float(norm_pt[0]), float(norm_pt[1])\n",
    "    x_px = int(np.clip(nx * width, 0, width - 1))\n",
    "    y_px = int(np.clip(ny * height, 0, height - 1))\n",
    "    return x_px, y_px\n",
    "\n",
    "def draw_text_box(img, text_lines, origin=(10,30), font_scale=0.45, thickness=1, max_width_ratio=0.45):\n",
    "    \"\"\"\n",
    "    Draw a semi-opaque text box with word wrapping.\n",
    "    \"\"\"\n",
    "    x0, y0 = origin\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    max_width_px = int(img.shape[1] * max_width_ratio)\n",
    "\n",
    "    wrapped_lines = []\n",
    "    for line in text_lines:\n",
    "        words = line.split(\" \")\n",
    "        current_line = \"\"\n",
    "        for word in words:\n",
    "            test_line = (current_line + \" \" + word).strip()\n",
    "            (tw, th), _ = cv2.getTextSize(test_line, font, font_scale, thickness)\n",
    "            if tw <= max_width_px or current_line == \"\":\n",
    "                current_line = test_line\n",
    "            else:\n",
    "                wrapped_lines.append(current_line)\n",
    "                current_line = word\n",
    "        if current_line:\n",
    "            wrapped_lines.append(current_line)\n",
    "\n",
    "    # Compute box size\n",
    "    w = 0\n",
    "    h = 0\n",
    "    line_heights = []\n",
    "    for line in wrapped_lines:\n",
    "        (tw, th), _ = cv2.getTextSize(line, font, font_scale, thickness)\n",
    "        w = max(w, tw)\n",
    "        h += th + 6\n",
    "        line_heights.append(th)\n",
    "\n",
    "    # Background rectangle (slightly transparent)\n",
    "    overlay = img.copy()\n",
    "    cv2.rectangle(overlay, (x0-6, y0-16), (x0+w+6, y0 + h), (0,0,0), -1)\n",
    "    alpha = 0.6\n",
    "    cv2.addWeighted(overlay, alpha, img, 1 - alpha, 0, img)\n",
    "\n",
    "    # Put text\n",
    "    y = y0\n",
    "    for i, line in enumerate(wrapped_lines):\n",
    "        cv2.putText(img, line, (x0, y), font, font_scale, (255,255,255), thickness, cv2.LINE_AA)\n",
    "        y += line_heights[i] + 6\n",
    "\n",
    "# ---------------- load data ----------------\n",
    "try:\n",
    "    landmarks_all = np.load(LANDMARKS_PATH)  # expected shape (F, 33, 3)\n",
    "except Exception as e:\n",
    "    raise RuntimeError(f\"Failed to load landmarks from {LANDMARKS_PATH}: {e}\")\n",
    "\n",
    "try:\n",
    "    df = pd.read_csv(METRICS_PATH, index_col='shot_idx')\n",
    "except Exception as e:\n",
    "    raise RuntimeError(f\"Failed to load metrics CSV from {METRICS_PATH}: {e}\")\n",
    "\n",
    "cap = cv2.VideoCapture(FILE_PATH)\n",
    "if not cap.isOpened():\n",
    "    raise RuntimeError(f\"Can't open video at {FILE_PATH}.\")\n",
    "\n",
    "fps = cap.get(cv2.CAP_PROP_FPS) or 30.0\n",
    "W = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "H = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "out = cv2.VideoWriter(OUTPUT_PATH, fourcc, fps, (W, H))\n",
    "\n",
    "# ---------------- Precompute per-shot diagnostics ----------------\n",
    "diagnostics = {}  # shot_idx -> dict\n",
    "\n",
    "for shot_idx, row in df.iterrows():\n",
    "    peak = int(row['frame_peak'])\n",
    "    start = int(row['frame_start'])\n",
    "    # shoulder span at peak (normalized)\n",
    "    coords_peak = landmarks_all[peak]\n",
    "    shoulder_span = dist(coords_peak[L.LEFT_SHOULDER.value], coords_peak[L.RIGHT_SHOULDER.value])\n",
    "    # stance width already in df (assumed normalized)\n",
    "    stance_w = row.get('stance_width', None)\n",
    "    stance_ratio = None\n",
    "    if stance_w is not None and shoulder_span > 0:\n",
    "        stance_ratio = stance_w / shoulder_span\n",
    "\n",
    "    # hold variance and symmetry already present in df\n",
    "    hold_var = row.get('hold_variance', 0.0)\n",
    "    symmetry = row.get('symmetry_diff', 0.0)\n",
    "\n",
    "    # Release jerk: compute change in elbow angle immediately after peak\n",
    "    left_angles = []\n",
    "    for f in range(peak, min(peak+4, landmarks_all.shape[0])):\n",
    "        c = landmarks_all[f]\n",
    "        a = angle_between(c[L.LEFT_SHOULDER.value], c[L.LEFT_ELBOW.value], c[L.LEFT_WRIST.value])\n",
    "        left_angles.append(a)\n",
    "    release_jerk = 0.0\n",
    "    if len(left_angles) >= 2:\n",
    "        release_jerk = max(abs(left_angles[i+1] - left_angles[i]) for i in range(len(left_angles)-1))\n",
    "\n",
    "    # head stability: stddev of nose during hold window\n",
    "    hold_start = max(start, peak - HOLD_WINDOW_FRAMES)\n",
    "    nose_positions = landmarks_all[hold_start:peak, L.NOSE.value] if peak > hold_start else np.array([])\n",
    "    head_std = 0.0\n",
    "    if len(nose_positions) > 0:\n",
    "        head_std = float(np.std(nose_positions[:,1]))\n",
    "\n",
    "    diagnostics[shot_idx] = {\n",
    "        \"shoulder_span\": float(shoulder_span),\n",
    "        \"stance_w\": float(stance_w) if stance_w is not None else None,\n",
    "        \"stance_ratio\": float(stance_ratio) if stance_ratio is not None else None,\n",
    "        \"hold_var\": float(hold_var),\n",
    "        \"symmetry\": float(symmetry),\n",
    "        \"release_jerk\": float(release_jerk),\n",
    "        \"head_std\": float(head_std),\n",
    "        \"frame_start\": int(start),\n",
    "        \"frame_peak\": int(peak)\n",
    "    }\n",
    "\n",
    "# ---------------- main overlay loop ----------------\n",
    "frame_idx = 0\n",
    "\n",
    "# Running buffers for short-window per-frame metrics\n",
    "angle_buf_L = deque(maxlen=HOLD_WINDOW_FRAMES+1)  # left elbow angles\n",
    "angle_buf_R = deque(maxlen=HOLD_WINDOW_FRAMES+1)  # right elbow angles\n",
    "nose_buf = deque(maxlen=HOLD_WINDOW_FRAMES)       # nose y positions (normalized)\n",
    "ankle_buf = deque(maxlen=HOLD_WINDOW_FRAMES)      # optional stance widths\n",
    "prev_left_angle = None\n",
    "prev_right_angle = None\n",
    "\n",
    "# Build shot lookup by frame range for quick per-frame shot mapping\n",
    "shots_by_frame = {}\n",
    "for shot_idx, diag in diagnostics.items():\n",
    "    s = int(diag['frame_start'])\n",
    "    p = int(diag['frame_peak'])\n",
    "    end = min(p + 10, landmarks_all.shape[0]-1)\n",
    "    for f in range(s, end+1):\n",
    "        shots_by_frame[f] = shot_idx\n",
    "\n",
    "cap.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    h, w = frame.shape[:2]\n",
    "    annotated = frame.copy()\n",
    "\n",
    "    if frame_idx < len(landmarks_all):\n",
    "        lm_norm = landmarks_all[frame_idx]  # (33,3)\n",
    "    else:\n",
    "        lm_norm = None\n",
    "\n",
    "    pix = {}\n",
    "    if lm_norm is not None:\n",
    "        # convert normalized to pixels for all landmarks (used for drawing always)\n",
    "        for i in range(lm_norm.shape[0]):\n",
    "            x_px, y_px = normalized_to_pixel(lm_norm[i], w, h)\n",
    "            pix[i] = (x_px, y_px)\n",
    "\n",
    "        # DRAW SKELETON (always visible when landmarks exist)\n",
    "        for a, b in solutions.pose.POSE_CONNECTIONS:\n",
    "            # ensure the indices exist in pix (some connections may reference indices not present)\n",
    "            ia = int(a)\n",
    "            ib = int(b)\n",
    "            if ia in pix and ib in pix:\n",
    "                pa = pix[ia]\n",
    "                pb = pix[ib]\n",
    "                cv2.line(annotated, pa, pb, (180, 180, 180), 2)\n",
    "\n",
    "        for i, (x, y) in pix.items():\n",
    "            cv2.circle(annotated, (x, y), 5, (200, 200, 200), -1)\n",
    "\n",
    "        # annotate left/right shoulders for orientation clarity (always visible)\n",
    "        for i in (L.LEFT_SHOULDER.value, L.RIGHT_SHOULDER.value):\n",
    "            if i in pix:\n",
    "                x, y = pix[i]\n",
    "                cv2.putText(annotated, 'L-S' if i==L.LEFT_SHOULDER.value else 'R-S',\n",
    "                            (x+6, y-6), cv2.FONT_HERSHEY_SIMPLEX, 0.4, (220,220,220), 1, cv2.LINE_AA)\n",
    "\n",
    "        # Draw an arrow showing target direction (optional): use vector from hips to nose as rough facing\n",
    "        hip_mid = ((lm_norm[L.LEFT_HIP.value] + lm_norm[L.RIGHT_HIP.value]) / 2.0)\n",
    "        nose = lm_norm[L.NOSE.value]\n",
    "        hip_px = normalized_to_pixel(hip_mid, w, h)\n",
    "        nose_px = normalized_to_pixel(nose, w, h)\n",
    "        cv2.arrowedLine(annotated, hip_px, nose_px, (255,200,0), 2, tipLength=0.15)\n",
    "\n",
    "        # -------------------\n",
    "        # Per-frame metric computation (running-window)\n",
    "        # -------------------\n",
    "        left_elbow_angle = angle_between(lm_norm[L.LEFT_SHOULDER.value],\n",
    "                                         lm_norm[L.LEFT_ELBOW.value],\n",
    "                                         lm_norm[L.LEFT_WRIST.value])\n",
    "        right_elbow_angle = angle_between(lm_norm[L.RIGHT_SHOULDER.value],\n",
    "                                          lm_norm[L.RIGHT_ELBOW.value],\n",
    "                                          lm_norm[L.RIGHT_WRIST.value])\n",
    "        angle_buf_L.append(left_elbow_angle)\n",
    "        angle_buf_R.append(right_elbow_angle)\n",
    "\n",
    "        # nose Y for head stability\n",
    "        nose_y = lm_norm[L.NOSE.value][1] if not np.any(np.isnan(lm_norm[L.NOSE.value])) else np.nan\n",
    "        nose_buf.append(nose_y)\n",
    "\n",
    "        # stance width here computed from ankles (normalized) if available\n",
    "        left_ankle = lm_norm[L.LEFT_ANKLE.value]\n",
    "        right_ankle = lm_norm[L.RIGHT_ANKLE.value]\n",
    "        stance_w_now = None\n",
    "        if not np.any(np.isnan(left_ankle)) and not np.any(np.isnan(right_ankle)):\n",
    "            stance_w_now = dist(left_ankle, right_ankle)\n",
    "        ankle_buf.append(stance_w_now)\n",
    "\n",
    "        # shoulder span for this frame (normalized)\n",
    "        shoulder_span_now = dist(lm_norm[L.LEFT_SHOULDER.value], lm_norm[L.RIGHT_SHOULDER.value])\n",
    "\n",
    "        # instantaneous stance ratio if possible\n",
    "        stance_ratio_now = None\n",
    "        if stance_w_now is not None and shoulder_span_now > 0:\n",
    "            stance_ratio_now = stance_w_now / shoulder_span_now\n",
    "\n",
    "        # symmetry (abs angle diff)\n",
    "        symmetry_now = abs(left_elbow_angle - right_elbow_angle)\n",
    "\n",
    "        # hold variance (short window std of left elbow angle as proxy)\n",
    "        hold_var_now = float(np.nanstd(np.array(angle_buf_L))) if len(angle_buf_L) > 1 else 0.0\n",
    "\n",
    "        # short-term release jerk approximation (max delta in last two frames)\n",
    "        release_jerk_now = 0.0\n",
    "        if prev_left_angle is not None and prev_right_angle is not None:\n",
    "            release_jerk_now = max(abs(left_elbow_angle - prev_left_angle),\n",
    "                                   abs(right_elbow_angle - prev_right_angle))\n",
    "\n",
    "        # head_std (normalized y std in nose_buf)\n",
    "        nose_arr = np.array([v for v in nose_buf if not np.isnan(v)]) if len(nose_buf) > 0 else np.array([])\n",
    "        head_std_now = float(np.std(nose_arr)) if len(nose_arr) > 1 else 0.0\n",
    "\n",
    "        prev_left_angle = left_elbow_angle\n",
    "        prev_right_angle = right_elbow_angle\n",
    "\n",
    "        # -------------------\n",
    "        # Build suggestions for this frame (always)\n",
    "        # -------------------\n",
    "        suggestions = []\n",
    "        bad_joints = []\n",
    "\n",
    "        if symmetry_now > TH_SYMMETRY_DEG:\n",
    "            suggestions.append(f\"Asymmetric arms: {symmetry_now:.1f}° difference\")\n",
    "            bad_joints += [L.LEFT_ELBOW.value, L.RIGHT_ELBOW.value]\n",
    "\n",
    "        if hold_var_now > TH_HOLD_VAR:\n",
    "            suggestions.append(f\"Anchor unstable (short window variance {hold_var_now:.2f})\")\n",
    "            bad_joints += [L.LEFT_WRIST.value, L.RIGHT_WRIST.value]\n",
    "\n",
    "        if stance_ratio_now is not None:\n",
    "            if stance_ratio_now < TH_STANCE_RATIO_MIN:\n",
    "                suggestions.append(\"Stance narrow (frame): widen feet\")\n",
    "                bad_joints += [L.LEFT_ANKLE.value, L.RIGHT_ANKLE.value]\n",
    "            elif stance_ratio_now > TH_STANCE_RATIO_MAX:\n",
    "                suggestions.append(\"Stance wide (frame): bring feet closer\")\n",
    "                bad_joints += [L.LEFT_ANKLE.value, L.RIGHT_ANKLE.value]\n",
    "\n",
    "        if release_jerk_now > TH_RELEASE_JERK:\n",
    "            suggestions.append(\"Sudden change in elbow angle (jerk) — smooth follow-through\")\n",
    "            bad_joints += [L.LEFT_WRIST.value, L.RIGHT_WRIST.value]\n",
    "\n",
    "        if head_std_now > 0.02:  # same threshold as earlier (tuneable)\n",
    "            suggestions.append(\"Head movement high (short window) — stabilize head\")\n",
    "            bad_joints += [L.NOSE.value]\n",
    "\n",
    "        # Merge shot-level suggestions if this frame belongs to a shot\n",
    "        if frame_idx in shots_by_frame:\n",
    "            shot_idx = shots_by_frame[frame_idx]\n",
    "            diag = diagnostics[shot_idx]\n",
    "            # Add shot-level messages if not already present\n",
    "            if diag['symmetry'] > TH_SYMMETRY_DEG:\n",
    "                msg = f\"Asymmetric draw (shot): {diag['symmetry']:.1f}°\"\n",
    "                if msg not in suggestions:\n",
    "                    suggestions.append(msg)\n",
    "                    bad_joints += [L.LEFT_ELBOW.value, L.RIGHT_ELBOW.value]\n",
    "            if diag['hold_var'] > TH_HOLD_VAR:\n",
    "                msg = \"Unstable anchor (shot)\"\n",
    "                if msg not in suggestions:\n",
    "                    suggestions.append(msg)\n",
    "                    bad_joints += [L.LEFT_WRIST.value, L.RIGHT_WRIST.value]\n",
    "            if diag['stance_ratio'] is not None:\n",
    "                if diag['stance_ratio'] < TH_STANCE_RATIO_MIN:\n",
    "                    msg = \"Stance too narrow (shot)\"\n",
    "                    if msg not in suggestions:\n",
    "                        suggestions.append(msg)\n",
    "                        bad_joints += [L.LEFT_ANKLE.value, L.RIGHT_ANKLE.value]\n",
    "                elif diag['stance_ratio'] > TH_STANCE_RATIO_MAX:\n",
    "                    msg = \"Stance too wide (shot)\"\n",
    "                    if msg not in suggestions:\n",
    "                        suggestions.append(msg)\n",
    "                        bad_joints += [L.LEFT_ANKLE.value, L.RIGHT_ANKLE.value]\n",
    "            if diag['release_jerk'] > TH_RELEASE_JERK:\n",
    "                msg = \"Jerky release (shot)\"\n",
    "                if msg not in suggestions:\n",
    "                    suggestions.append(msg)\n",
    "                    bad_joints += [L.LEFT_WRIST.value]\n",
    "            if diag['head_std'] > 0.02:\n",
    "                msg = \"Head movement high (shot)\"\n",
    "                if msg not in suggestions:\n",
    "                    suggestions.append(msg)\n",
    "                    bad_joints += [L.NOSE.value]\n",
    "\n",
    "            # Shot label/metadata\n",
    "            cv2.putText(annotated, f\"Shot {shot_idx} Frame {frame_idx}\", (10, H-20),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255,255,255), 2, cv2.LINE_AA)\n",
    "\n",
    "        # Positive message if nothing bad\n",
    "        if len(suggestions) == 0:\n",
    "            suggestions = [\"No major issues detected — good posture!\"]\n",
    "\n",
    "        # Re-draw joints with shot-specific coloring (green by default, red for bad joints)\n",
    "        for i, (x, y) in pix.items():\n",
    "            color = (0,255,0) if i not in bad_joints else (0,0,255)\n",
    "            cv2.circle(annotated, (x,y), 6, color, -1)\n",
    "\n",
    "        # Overwrite bones to make frame stand out\n",
    "        for a, b in solutions.pose.POSE_CONNECTIONS:\n",
    "            ia = int(a); ib = int(b)\n",
    "            if ia in pix and ib in pix:\n",
    "                cv2.line(annotated, pix[ia], pix[ib], (200,200,200), 2)\n",
    "\n",
    "        # Put suggestions text box (always visible when landmarks exist)\n",
    "        draw_text_box(annotated, suggestions, origin=(10,30))\n",
    "\n",
    "    # Draw frame index\n",
    "    cv2.putText(annotated, f\"Frame {frame_idx}\", (W-160, 20),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255,255,255), 1, cv2.LINE_AA)\n",
    "\n",
    "    out.write(annotated)\n",
    "    frame_idx += 1\n",
    "\n",
    "cap.release()\n",
    "out.release()\n",
    "print(\"Saved annotated video to:\", OUTPUT_PATH)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
